/**
 * MÃ³dulo de rotas da API REST
 * 
 * Este mÃ³dulo contÃ©m todas as rotas HTTP da aplicaÃ§Ã£o,
 * separadas da lÃ³gica do servidor principal para melhor organizaÃ§Ã£o.
 */

import { Router, Request, Response } from 'express';
import { Server } from 'socket.io';
import { getAllConnections, getConnection } from '../services/connectionService';
import { getAgentsConfig } from '../agents/config';
import {
  AgentCrudError,
  AgentCreatePayload,
  AgentUpdatePayload,
  createAgent,
  deleteAgent,
  getAgentsFile,
  updateAgent,
} from '../agents/agentCrudService';
import { loadTokens } from '../storage/tokenStorage';
import { loadLogs, saveFrontendLog, loadFrontendLogs } from '../storage/logStorage';
import { clearConversation, loadConversation } from '../storage/conversationStorage';
import { getCurrentLLMProvider } from '../services/llmService';
import { loadConfigFromJson, saveConfigToJson, AppConfig } from '../config/env';
import { validateLLMCredentials } from '../validation/credentialValidator';
import { updateLLMConfig, initializeLLMAdapter, getLLMAdapter } from '../services/llmService';
import { LLMProvider } from '../types';
import { LLMAdapter } from '../llm/adapters/LLMAdapter';
import { AgentManager } from '../agents/agentManager';
import { initializeAgents } from '../agents/config';
import { setThreadId } from '../services/threadService';
import {
  getAllModels,
  getModelsByProvider,
  updateProviderModels,
  updateAllProviderModels,
  shouldUpdateProvider,
  loadModelsDatabase,
} from '../services/modelService';

/**
 * DependÃªncias necessÃ¡rias para as rotas
 */
export interface ApiRoutesDependencies {
  io: Server;
  getLLMAdapter: () => LLMAdapter | null;
  getAgentManager: () => AgentManager | null;
  setAgentManager: (manager: AgentManager) => void;
}

/**
 * Cria e configura todas as rotas da API
 * 
 * @param app - InstÃ¢ncia do Express Router
 * @param deps - DependÃªncias necessÃ¡rias para as rotas
 */
export function setupApiRoutes(app: Router, deps: ApiRoutesDependencies): void {
  /**
   * Helper de tratamento de erro para operaÃ§Ãµes de agentes.
   */
  const handleAgentError = (res: Response, error: unknown) => {
    if (error instanceof AgentCrudError) {
      return res.status(error.status).json({ error: error.message });
    }
    console.error('Erro inesperado ao manipular agentes:', error);
    return res.status(500).json({ error: 'Erro interno ao manipular agentes.' });
  };

  /**
   * API: Lista todas as conexÃµes ativas
   */
  app.get('/api/connections', (req: Request, res: Response) => {
    const connections = getAllConnections().map(conn => ({
      socketId: conn.socketId,
      threadId: conn.threadId,
      connectedAt: conn.connectedAt.toISOString(),
      lastActivity: conn.lastActivity.toISOString(),
      messageCount: conn.messageCount,
      userAgent: conn.userAgent,
      ipAddress: conn.ipAddress
    }));
    res.json({ connections });
  });

  /**
   * API: ObtÃ©m informaÃ§Ãµes de uma conexÃ£o especÃ­fica
   */
  app.get('/api/connections/:socketId', (req: Request, res: Response) => {
    const { socketId } = req.params;
    const connection = getConnection(socketId);
    if (!connection) {
      return res.status(404).json({ error: 'ConexÃ£o nÃ£o encontrada' });
    }
    res.json({
      socketId: connection.socketId,
      threadId: connection.threadId,
      connectedAt: connection.connectedAt.toISOString(),
      lastActivity: connection.lastActivity.toISOString(),
      messageCount: connection.messageCount,
      userAgent: connection.userAgent,
      ipAddress: connection.ipAddress
    });
  });

  /**
   * API: Lista todos os agentes disponÃ­veis
   */
  app.get('/api/agents', async (req: Request, res: Response) => {
    try {
      const agents = getAgentsConfig();
      
      // Formata agentes para resposta (lista plana)
      const formattedAgents = agents.map(agent => {
        const agentAny = agent as any;
        return {
          name: agent.name,
          description: agent.description,
          model: agent.model,
          priority: agentAny.priority ?? 999,
          toolsCount: agent.tools.length,
          tools: agent.tools.map((tool: any) => {
            if (tool.type === 'function' && tool.function) {
              return tool.function.name;
            }
            return 'unknown';
          }).filter(Boolean),
          ...(agentAny.stackspotAgentId && { stackspotAgentId: agentAny.stackspotAgentId }),
        };
      });
      
      res.json({
        agents: formattedAgents,
      });
    } catch (error: any) {
      console.error('Erro ao obter agentes:', error);
      res.status(500).json({ error: 'Erro ao obter lista de agentes' });
    }
  });

  /**
   * API: ObtÃ©m o conteÃºdo bruto do arquivo agents.json (lista plana)
   */
  app.get('/api/agents/config', async (_req: Request, res: Response) => {
    try {
      console.log('ðŸ“¥ Recebida requisiÃ§Ã£o GET /api/agents/config');
      const agentsFile = await getAgentsFile();
      console.log('âœ… Agentes carregados com sucesso');
      return res.json(agentsFile);
    } catch (error) {
      console.error('âŒ Erro ao obter agentes:', error);
      if (error instanceof AgentCrudError) {
        console.error('âŒ AgentCrudError:', error.message, 'Status:', error.status);
        return res.status(error.status).json({ error: error.message });
      }
      const errorMessage = error instanceof Error ? error.message : 'Erro desconhecido ao obter configuraÃ§Ã£o de agentes';
      const errorStack = error instanceof Error ? error.stack : undefined;
      console.error('âŒ Detalhes do erro:', errorMessage);
      console.error('âŒ Stack:', errorStack);
      return res.status(500).json({ 
        error: errorMessage,
        details: errorStack
      });
    }
  });

  /**
   * API: Cria um novo agente (sem grupos).
   */
  app.post('/api/agents', async (req: Request, res: Response) => {
    try {
      const payload = req.body as AgentCreatePayload;
      const created = await createAgent(payload);
      res.status(201).json(created);
    } catch (error) {
      handleAgentError(res, error);
    }
  });

  /**
   * API: Atualiza um agente existente (sem grupos).
   */
  app.put('/api/agents/:agentName', async (req: Request, res: Response) => {
    try {
      const agentName = decodeURIComponent(req.params.agentName);
      const updates = req.body as AgentUpdatePayload;
      const updated = await updateAgent(agentName, updates);
      res.json(updated);
    } catch (error) {
      handleAgentError(res, error);
    }
  });

  /**
   * API: Remove um agente (sem grupos).
   */
  app.delete('/api/agents/:agentName', async (req: Request, res: Response) => {
    try {
      const agentName = decodeURIComponent(req.params.agentName);
      await deleteAgent(agentName);
      res.json({ success: true });
    } catch (error) {
      handleAgentError(res, error);
    }
  });

  /**
   * API: ObtÃ©m histÃ³rico de tokens
   */
  app.get('/api/tokens', async (req: Request, res: Response) => {
    try {
      // ObtÃ©m o provider para filtrar (query param ou provider atual)
      const requestedProvider = req.query.llmProvider as string | undefined;
      const filterProvider = (requestedProvider as LLMProvider) || getCurrentLLMProvider();
      
      // Usa funÃ§Ã£o do mÃ³dulo de storage que jÃ¡ filtra e recalcula
      const tokensData = loadTokens(filterProvider);
      
      res.json({
        totalTokens: tokensData.totalTokens,
        totalCost: tokensData.totalCost,
        entries: tokensData.entries,
        lastUpdated: tokensData.lastUpdated,
        filteredBy: filterProvider
      });
    } catch (error: any) {
      console.error('Erro ao obter tokens:', error);
      res.status(500).json({ error: 'Erro ao obter histÃ³rico de tokens' });
    }
  });

  /**
   * API: Recebe logs do frontend
   */
  app.post('/api/logs/frontend', async (req: Request, res: Response) => {
    try {
      const { level, message, data, timestamp, source } = req.body;
      
      const logEntry = {
        id: `frontend_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        timestamp: timestamp || new Date().toISOString(),
        level: level || 'info',
        message: message || 'Log do frontend',
        data: data || {},
        source: source || 'frontend',
        userAgent: req.headers['user-agent'],
        ip: req.ip || req.socket.remoteAddress,
      };
      
      // Salva no console do backend
      const logMessage = `[Frontend] ${logEntry.level.toUpperCase()}: ${logEntry.message}`;
      if (logEntry.data && Object.keys(logEntry.data).length > 0) {
        console.log(logMessage, logEntry.data);
      } else {
        console.log(logMessage);
      }
      
      // Salva em arquivo de log
      saveFrontendLog(logEntry);
      
      res.json({ success: true, received: true });
    } catch (error) {
      console.error('Erro ao receber log do frontend:', error);
      res.status(500).json({ error: 'Erro ao processar log do frontend' });
    }
  });

  /**
   * API: ObtÃ©m logs do frontend
   */
  app.get('/api/logs/frontend', async (req: Request, res: Response) => {
    try {
      const limit = req.query.limit ? parseInt(req.query.limit as string, 10) : 1000;
      const level = req.query.level as string | undefined;
      
      let logs = loadFrontendLogs(limit);
      
      // Filtra por nÃ­vel se especificado
      if (level && ['debug', 'info', 'warn', 'error'].includes(level)) {
        logs = logs.filter(log => log.level === level);
      }
      
      res.json({ 
        logs,
        total: logs.length,
        limit,
        level: level || 'all',
      });
    } catch (error) {
      console.error('Erro ao obter logs do frontend:', error);
      res.status(500).json({ error: 'Erro ao obter logs do frontend' });
    }
  });

  /**
   * API: ObtÃ©m histÃ³rico de logs
   */
  app.get('/api/logs', async (req: Request, res: Response) => {
    try {
      // ObtÃ©m o provider para filtrar (query param ou provider atual)
      const requestedProvider = req.query.llmProvider as string | undefined;
      const filterProvider = (requestedProvider as LLMProvider) || getCurrentLLMProvider();
      
      // Usa funÃ§Ã£o do mÃ³dulo de storage que jÃ¡ filtra e recalcula estatÃ­sticas
      const logsData = loadLogs(filterProvider);
      
      res.json({
        totalEntries: logsData.totalEntries,
        entries: logsData.entries,
        lastUpdated: logsData.lastUpdated,
        statistics: logsData.statistics,
        filteredBy: filterProvider
      });
    } catch (error: any) {
      console.error('Erro ao obter logs:', error);
      res.status(500).json({ error: 'Erro ao obter histÃ³rico de logs' });
    }
  });

  /**
   * API: Limpa conversa de uma thread
   */
  app.delete('/api/conversations/:threadId', async (req: Request, res: Response) => {
    try {
      const { threadId } = req.params;
      clearConversation(threadId);
      res.json({ success: true, message: 'Conversa limpa com sucesso' });
    } catch (error: any) {
      console.error('Erro ao limpar conversa:', error);
      res.status(500).json({ error: 'Erro ao limpar conversa' });
    }
  });

  /**
   * API: Carrega conversa de uma thread
   */
  app.get('/api/conversations/:threadId', async (req: Request, res: Response) => {
    try {
      const { threadId } = req.params;
      const conversation = loadConversation(threadId);
      if (!conversation) {
        return res.json({ messages: [], llmProvider: null });
      }
      res.json({ 
        messages: conversation.messages,
        llmProvider: conversation.llmProvider || getCurrentLLMProvider()
      });
    } catch (error: any) {
      console.error('Erro ao carregar conversa:', error);
      res.status(500).json({ error: 'Erro ao carregar conversa' });
    }
  });

  /**
   * API: ObtÃ©m configuraÃ§Ã£o atual
   */
  app.get('/api/config', async (req: Request, res: Response) => {
    try {
      const config = loadConfigFromJson();
      
      // Prepara resposta com informaÃ§Ãµes de OpenAI
      let openaiConfig: any = {
        configured: false,
        apiKeyPreview: null
      };
      
      if (config?.openaiApiKey) {
        const maskedKey = config.openaiApiKey.substring(0, 7) + '...' + config.openaiApiKey.substring(config.openaiApiKey.length - 4);
        openaiConfig = {
          configured: true,
          apiKeyPreview: maskedKey
        };
      }
      
      // Prepara resposta com informaÃ§Ãµes de StackSpot
      let stackspotConfig: any = {
        configured: false,
        clientIdPreview: null,
        realm: 'stackspot-freemium'
      };
      
      if (config?.stackspotClientId && config?.stackspotClientSecret) {
        const maskedClientId = config.stackspotClientId.substring(0, 8) + '...' + config.stackspotClientId.substring(config.stackspotClientId.length - 4);
        stackspotConfig = {
          configured: true,
          clientIdPreview: maskedClientId,
          realm: config.stackspotRealm || 'stackspot-freemium'
        };
      }
      
      // Prepara resposta com informaÃ§Ãµes de Ollama
      let ollamaConfig: any = {
        configured: true, // Ollama nÃ£o precisa de credenciais
        baseUrl: config?.ollamaBaseUrl || 'http://localhost:11434',
        defaultModel: config?.ollamaDefaultModel || 'llama2'
      };
      
      // Retorna formato completo esperado pelo frontend
      res.json({
        llmProvider: config?.llmProvider || 'stackspot',
        openai: openaiConfig,
        stackspot: stackspotConfig,
        ollama: ollamaConfig,
        port: config?.port || 3000,
        lastUpdated: config?.lastUpdated || null
      });
    } catch (error: any) {
      console.error('Erro ao obter configuraÃ§Ã£o:', error);
      res.status(500).json({ error: 'Erro ao obter configuraÃ§Ã£o' });
    }
  });

  /**
   * API: Salva configuraÃ§Ã£o (suporta OpenAI e StackSpot)
   */
  app.post('/api/config', async (req: Request, res: Response) => {
    try {
      const { llmProvider, openaiApiKey, stackspotClientId, stackspotClientSecret, stackspotRealm, ollamaBaseUrl, ollamaDefaultModel, port } = req.body;
      
      // Valida provider
      if (!llmProvider || (llmProvider !== 'openai' && llmProvider !== 'stackspot' && llmProvider !== 'ollama')) {
        return res.status(400).json({ error: 'Provider deve ser "openai", "stackspot" ou "ollama"' });
      }
      
      // Valida credenciais apenas do provider que estÃ¡ sendo configurado
      // Permite salvar apenas o provider sem precisar das credenciais (para alternar entre providers)
      if (llmProvider === 'openai' && openaiApiKey) {
        if (typeof openaiApiKey !== 'string' || openaiApiKey.trim() === '') {
          return res.status(400).json({ error: 'OpenAI API key invÃ¡lida' });
        }
        if (!openaiApiKey.startsWith('sk-')) {
          return res.status(400).json({ error: 'OpenAI API key invÃ¡lida. Deve comeÃ§ar com "sk-"' });
        }
      } else if (llmProvider === 'stackspot') {
        // Para StackSpot, se estiver fornecendo credenciais, valida ambas
        if (stackspotClientId || stackspotClientSecret) {
          if (!stackspotClientId || typeof stackspotClientId !== 'string' || stackspotClientId.trim() === '') {
            return res.status(400).json({ error: 'StackSpot Client ID Ã© obrigatÃ³rio quando fornecendo credenciais' });
          }
          if (!stackspotClientSecret || typeof stackspotClientSecret !== 'string' || stackspotClientSecret.trim() === '') {
            return res.status(400).json({ error: 'StackSpot Client Secret Ã© obrigatÃ³rio quando fornecendo credenciais' });
          }
        }
      }
      
      // Se estiver apenas mudando o provider sem fornecer credenciais novas,
      // verifica se jÃ¡ existem credenciais salvas para o provider escolhido
      const existingConfig = loadConfigFromJson() || {};
      if (llmProvider === 'openai' && !openaiApiKey && !existingConfig.openaiApiKey) {
        return res.status(400).json({ error: 'OpenAI API key Ã© obrigatÃ³ria. ForneÃ§a uma API key para configurar o OpenAI.' });
      }
      if (llmProvider === 'stackspot' && !stackspotClientId && !existingConfig.stackspotClientId) {
        return res.status(400).json({ error: 'StackSpot Client ID e Client Secret sÃ£o obrigatÃ³rios. ForneÃ§a as credenciais para configurar o StackSpot.' });
      }
      // Ollama nÃ£o precisa de credenciais, sempre pode ser selecionado
      
      // Atualiza configuraÃ§Ã£o preservando todas as credenciais existentes
      const newConfig: AppConfig = {
        ...existingConfig,
        llmProvider: llmProvider as 'openai' | 'stackspot' | 'ollama',
        port: port || existingConfig.port || 3000
      };
      
      // Atualiza apenas as credenciais do provider selecionado, mantendo as outras
      if (llmProvider === 'openai') {
        if (openaiApiKey) {
          newConfig.openaiApiKey = openaiApiKey.trim();
        }
        // MantÃ©m credenciais dos outros providers se existirem
      } else if (llmProvider === 'stackspot') {
        if (stackspotClientId) {
          newConfig.stackspotClientId = stackspotClientId.trim();
        }
        if (stackspotClientSecret) {
          newConfig.stackspotClientSecret = stackspotClientSecret.trim();
        }
        if (stackspotRealm) {
          newConfig.stackspotRealm = stackspotRealm.trim() || 'stackspot-freemium';
        }
        // MantÃ©m credenciais dos outros providers se existirem
      } else if (llmProvider === 'ollama') {
        if (ollamaBaseUrl) {
          newConfig.ollamaBaseUrl = ollamaBaseUrl.trim();
        }
        if (ollamaDefaultModel) {
          newConfig.ollamaDefaultModel = ollamaDefaultModel.trim();
        }
        // MantÃ©m credenciais dos outros providers se existirem
      }
      
      // Valida credenciais antes de salvar e reinicializar
      const providerToValidate = (newConfig.llmProvider ?? llmProvider) as LLMProvider;
      const validation = validateLLMCredentials(providerToValidate, newConfig);
      if (!validation.valid) {
        return res.status(400).json({ 
          success: false,
          error: validation.error || 'Credenciais invÃ¡lidas para o provider selecionado'
        });
      }
      
      // Salva no config.json
      saveConfigToJson(newConfig);
      
      // Atualiza variÃ¡veis de ambiente baseado no provider ativo
      // MantÃ©m ambas as configuraÃ§Ãµes no JSON, mas usa apenas o provider selecionado
      if (llmProvider === 'openai' && newConfig.openaiApiKey) {
        process.env.OPENAI_API_KEY = newConfig.openaiApiKey;
      }
      // NÃ£o deleta OPENAI_API_KEY mesmo se mudar para StackSpot, pois pode ser usado depois
      
      if (newConfig.port) {
        process.env.PORT = newConfig.port.toString();
      }
      
      // Reinicializa adaptador LLM (jÃ¡ validado acima)
      await initializeLLMAdapter();
      
      // Verifica se o adapter foi inicializado com sucesso
      const llmAdapter = deps.getLLMAdapter();
      if (!llmAdapter) {
        return res.status(500).json({ 
          success: false,
          error: `NÃ£o foi possÃ­vel inicializar o adaptador ${llmProvider}. Verifique as credenciais.`
        });
      }
      
      // Recria AgentManager com novo adaptador LLM
      const agentManager = new AgentManager(llmAdapter);
      deps.setAgentManager(agentManager);
      
      // Reinicializa agentes com o novo adaptador
      initializeAgents().catch((err: any) => {
        console.error('âŒ Erro ao reinicializar agentes:', err);
      });
      
      // Cria threads para sockets que estavam pendentes (sem credenciais)
      // Nota: Isso agora Ã© gerenciado pelos handlers Socket.IO
      const currentAdapter = llmAdapter;
      if (currentAdapter) {
        deps.io.sockets.sockets.forEach(async (socket) => {
          const connInfo = getConnection(socket.id);
          if (connInfo && connInfo.threadId === 'pending') {
            try {
              const thread = await currentAdapter.createThread();
              setThreadId(socket.id, thread.id);
              
              // Emite mensagem de sucesso
              const providerName = llmProvider === 'openai' ? 'OpenAI' : llmProvider === 'stackspot' ? 'StackSpot' : 'Ollama';
              socket.emit('config_saved', {
                type: 'config_saved',
                message: `âœ… ${providerName} configurado com sucesso!`,
                details: 'Agora vocÃª pode usar o DelsucIA normalmente.',
                timestamp: new Date().toISOString()
              });
              
              console.log(`âœ… Thread criada para socket pendente ${socket.id}: ${thread.id}`);
            } catch (error) {
              console.error(`âŒ Erro ao criar thread para socket ${socket.id}:`, error);
            }
          }
        });
      }
      
      // Prepara resposta com preview das credenciais
      let credentialPreview = '';
      if (llmProvider === 'openai' && newConfig.openaiApiKey) {
        credentialPreview = newConfig.openaiApiKey.substring(0, 7) + '...' + newConfig.openaiApiKey.substring(newConfig.openaiApiKey.length - 4);
      } else if (llmProvider === 'stackspot' && newConfig.stackspotClientId) {
        credentialPreview = newConfig.stackspotClientId.substring(0, 8) + '...' + newConfig.stackspotClientId.substring(newConfig.stackspotClientId.length - 4);
      } else if (llmProvider === 'ollama') {
        credentialPreview = `${newConfig.ollamaBaseUrl || 'http://localhost:11434'} (${newConfig.ollamaDefaultModel || 'llama2'})`;
      }
      
      res.json({
        success: true,
        message: 'ConfiguraÃ§Ã£o salva com sucesso',
        llmProvider: newConfig.llmProvider,
        credentialPreview
      });
    } catch (error: any) {
      console.error('Erro ao salvar configuraÃ§Ã£o:', error);
      res.status(500).json({ error: error.message || 'Erro ao salvar configuraÃ§Ã£o' });
    }
  });

  // ==================== Rotas de Modelos ====================
  
  /**
   * GET /api/models
   * Lista todos os modelos disponÃ­veis
   */
  app.get('/api/models', async (_req: Request, res: Response) => {
    try {
      const models = getAllModels();
      const db = loadModelsDatabase();
      
      res.json({
        success: true,
        models,
        providers: db.providers,
        lastUpdated: db.lastUpdated,
      });
    } catch (error: any) {
      console.error('Erro ao buscar modelos:', error);
      res.status(500).json({ error: error.message || 'Erro ao buscar modelos' });
    }
  });

  /**
   * GET /api/models/:provider
   * Lista modelos de um provider especÃ­fico
   */
  app.get('/api/models/:provider', async (req: Request, res: Response) => {
    try {
      const provider = req.params.provider as 'openai' | 'stackspot' | 'ollama';
      
      if (!['openai', 'stackspot', 'ollama'].includes(provider)) {
        return res.status(400).json({ error: 'Provider invÃ¡lido. Use: openai, stackspot ou ollama' });
      }

      const models = getModelsByProvider(provider);
      const db = loadModelsDatabase();
      const providerInfo = db.providers[provider];
      
      res.json({
        success: true,
        provider,
        models,
        lastFetched: providerInfo?.lastFetched || null,
        count: models.length,
        shouldUpdate: shouldUpdateProvider(provider),
      });
    } catch (error: any) {
      console.error('Erro ao buscar modelos do provider:', error);
      res.status(500).json({ error: error.message || 'Erro ao buscar modelos' });
    }
  });

  /**
   * POST /api/models/update/:provider
   * Atualiza modelos de um provider especÃ­fico
   */
  app.post('/api/models/update/:provider', async (req: Request, res: Response) => {
    try {
      const provider = req.params.provider as 'openai' | 'stackspot' | 'ollama';
      
      if (!['openai', 'stackspot', 'ollama'].includes(provider)) {
        return res.status(400).json({ error: 'Provider invÃ¡lido. Use: openai, stackspot ou ollama' });
      }

      const count = await updateProviderModels(provider);
      const models = getModelsByProvider(provider);
      
      res.json({
        success: true,
        message: `${count} modelo(s) do ${provider} atualizado(s) com sucesso`,
        provider,
        count,
        models,
      });
    } catch (error: any) {
      console.error('Erro ao atualizar modelos:', error);
      res.status(500).json({ error: error.message || 'Erro ao atualizar modelos' });
    }
  });

  /**
   * POST /api/models/update-all
   * Atualiza modelos de todos os providers
   */
  app.post('/api/models/update-all', async (_req: Request, res: Response) => {
    try {
      const results = await updateAllProviderModels();
      const db = loadModelsDatabase();
      
      res.json({
        success: true,
        message: 'Modelos atualizados com sucesso',
        results,
        providers: db.providers,
        totalModels: getAllModels().length,
      });
    } catch (error: any) {
      console.error('Erro ao atualizar todos os modelos:', error);
      res.status(500).json({ error: error.message || 'Erro ao atualizar modelos' });
    }
  });
}
